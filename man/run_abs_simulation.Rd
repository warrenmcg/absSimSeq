% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/abs_simulation.R
\name{run_abs_simulation}
\alias{run_abs_simulation}
\title{Run a copy number simulation}
\usage{
run_abs_simulation(fasta_file, sleuth_file, sample_index = 1,
  host = "dec2016.archive.ensembl.org", species = "hsapiens",
  outdir = ".", num_reps = c(10, 10), denom = NULL, seed = 1,
  num_runs = 1, gc_bias = NULL, de_probs = 0.1,
  de_type = "discrete", de_levels = c(1.25, 2, 4), dir_probs = 0.5,
  mean_lib_size = 20 * 10^6, single_value = TRUE,
  polyester_sim = FALSE, control_condition = NULL, num_cores = 1,
  include_spikeins = TRUE, spikein_mix = "Mix1",
  spikein_percent = 0.02)
}
\arguments{
\item{fasta_file, }{a multiFASTA file with the transcripts to be used in
the simulation (required for polyester)}

\item{sleuth_file, }{a R-Data file containing the sleuth object containing
results from a real experiment. If 'sleuth_save' is \code{FALSE}, the 
sleuth object will be loaded using \code{load}, and the name of the
sleuth object is expected to be 'sleuth.obj'.}

\item{sample_index, }{which sample from the real dataset should be used
as the starting point for the simulation? You may use a number or string,
as long as it is a valid column index for the dataset. If "mean" is given,
then the mean of the control samples will be used.}

\item{host, }{the URL to be used to download annotations using biomaRt.
the default is the archive URL for Ensembl V87.}

\item{species, }{the abbreviated latin name of the species (default 
"hsapiens"); used by biomaRt to get the annotations}

\item{outdir, }{where should the simulated reads be written to?}

\item{num_reps, }{the number of samples in each condition. Note that this
only currently supports two conditions, so this must be length 2.}

\item{denom, }{the name(s) of transcript(s) that will be used as the
denominator for showing how the data will behave after ALR transformation.
The default is \code{NULL}, which indicates that this function will choose
the first feature that is simulated to not change as the denominator.}

\item{seed, }{the random seed to be used for reproducibility}

\item{num_runs, }{the number of simulations to run}

\item{gc_bias, }{integer vector of length \code{sum(num_reps)} of the
GC bias to be used by polyester. Only numbers between 0 and 7.
See ?polyester::simulate_experiment under "gcbias" in the 
Details section for more information. The default is \code{NULL},
which means that all samples will be set to 0 (i.e. no bias).}

\item{de_probs, }{vector of same length as \code{num_runs}, with
numbers between 0 and 1 describing the probability of differential
expression for each simulation}

\item{de_type, }{either "discrete" or "normal" to indicate using
discrete levels of differential expression, or to used a truncated
normal for a continuum of differential expression. The levels of
discrete DE, or the parameters for the truncated normal, are
determined by \code{de_levels}.}

\item{de_levels, }{if \code{de_type} is "discrete", this is a vector
with one or more numbers > 1 to indicate the levels of differential
expression (e.g. 50% increase would be 1.5). If \code{de_type} is
"normal", this is a vector of length 3 specifying the following
parameters for the \code{rtruncnorm} function: a (the min of
the truncated normal; it should be > 1), mean, and sd.
When the direction is down, the inverse of these levels will be used.}

\item{dir_probs, }{vector of same length as \code{num_runs}, with
numbers between 0 and 1 describing the probability of differential
expression being increased, given a transcript that is changing.}

\item{mean_lib_size, }{the average number of reads per library to be
simulated. Variability in the exact library size per sample will
be introduced with a normal using a coefficient of variation of 5%.
(default is 20 million reads).}

\item{single_value, }{if \code{TRUE}, sizes are calculated for the whole
experiment using DESeq2 estimateDispersions; otherwise, sizes are
interpolated using the dispersion function from DESeq2 using the mean
counts for each condition.}

\item{polyester_sim, }{should polyester be run? (default to \code{FALSE}
to save time when you are merely interested in the ground truth)}

\item{control_condition, }{what factor level should be used to define
the control condition? This is used to select control samples to
estimate dispersions for a null distribution, i.e. variance of estimated
counts in an experiment without an expectation of differential expression.
The default, \code{NULL}, uses all of the samples in the provided sleuth_file.
Note that if this is specified, DESeq2 will estimate dispersions using an
intercept only model (~1), whereas if it is left \code{NULL}, the full
formula from the sleuth object will be used (obj$full_formula).}

\item{num_cores}{the number of cores to be used to run parallel simulations.
the default is to use just one.}

\item{include_spikeins}{if \code{TRUE}, will add spike-ins to the simulated
experiment.}

\item{spikein_mix}{character specifying which mix to use; only accepts
"Mix1" or "Mix2". If a different mix is desired for each condition, specify
a character vector containing a mix for each condition. The default is
"Mix1".}

\item{spikein_percent}{what percent of the total copy numbers in the control
condition should be spike-in controls? The default is 2\%.}
}
\value{
list with two members:
  \itemize{
    \item results: a list of lists, one entry for each simulation. Each
      simulation's results has the following entries:
      \itemize{
        \item all of the entries returned by \code{generate_abs_changes}
        \item sizes: the size parameter for each transcript
        \item expected_reads: an N x 2 matrix with the expected number of
          fragments for each transcript in each condition
        \item adjusted_consistent_changes: consistency comparing copy numbers
          to the relative data after normalization using the DESeq procedure
        \item adjusted_fold_changes: the fold changes perceived after normalization
          using the DESeq procedure
      }
    \item alr_data: a list of lists, one entry for each simulation. Each
      simulation's alr_data list contains the results from
      \code{calculate_rel_consistency}
  }
}
\description{
This function runs a simulation that explicitly defines copy numbers,
which can be used to test whether compositional changes leads to consistent
or misleading results based on the analysis done. After simulating an
experiment using the copy numbers, those numbers are converted into
expected reads to be used for a polyester simulation.
}
